{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbdb8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d973116",
   "metadata": {},
   "source": [
    "# Dataset-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31afabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1298988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = load_breast_cancer()\n",
    "data1['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420d7169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8154164e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1       2       3        4        5        6        7       8   \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "          9   ...      20     21      22      23       24       25      26  \\\n",
       "0    0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.05667  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.09744  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.05883  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.05623  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.05533  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05648  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.07016  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.05884  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         27      28       29  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data1.data#.info()\n",
    "X = pd.DataFrame(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3380e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data1.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aad8199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split_data(X, y, test_size):\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727f2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "        \"20/80\": stratified_split_data(X, y, test_size=0.8),\n",
    "        \"50/50\": stratified_split_data(X, y, test_size=0.5),\n",
    "        \"80/20\": stratified_split_data(X, y, test_size=0.2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ee2049",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5cda25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c3897af",
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [None, 10, 20]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74bebaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(clf, params, X_train, X_test, y_train, y_test):\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(clf, param_grid=params, cv=StratifiedKFold(3), scoring=\"accuracy\", return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Training error\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_error = 1 - train_accuracy\n",
    "\n",
    "    # Validation error (mean across folds)\n",
    "    validation_error = 1 - grid_search.best_score_\n",
    "\n",
    "    # Testing error\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_error = 1 - test_accuracy\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f} (Error: {train_error:.4f})\")\n",
    "    print(f\"Validation Accuracy: {grid_search.best_score_:.4f} (Error: {validation_error:.4f})\")\n",
    "    print(f\"Testing Accuracy: {test_accuracy:.4f} (Error: {test_error:.4f})\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_pred)}\")\n",
    "\n",
    "    return {\n",
    "        \"train_error\": train_error,\n",
    "        \"validation_error\": validation_error,\n",
    "        \"test_error\": test_error,\n",
    "        \"best_params\": grid_search.best_params_\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac1412",
   "metadata": {},
   "source": [
    "### Getting Accuracy reports for our different training/test split for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d806be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.9644 (Error: 0.0356)\n",
      "Testing Accuracy: 0.9364 (Error: 0.0636)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91       170\n",
      "           1       0.92      0.99      0.95       286\n",
      "\n",
      "    accuracy                           0.94       456\n",
      "   macro avg       0.95      0.92      0.93       456\n",
      "weighted avg       0.94      0.94      0.94       456\n",
      "\n",
      "Confusion Matrix:\n",
      "[[144  26]\n",
      " [  3 283]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.03556187766714081), 'test_error': 0.0635964912280702, 'best_params': {'max_depth': None, 'n_estimators': 200}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 50}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.9682 (Error: 0.0318)\n",
      "Testing Accuracy: 0.9474 (Error: 0.0526)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       106\n",
      "           1       0.96      0.96      0.96       179\n",
      "\n",
      "    accuracy                           0.95       285\n",
      "   macro avg       0.94      0.94      0.94       285\n",
      "weighted avg       0.95      0.95      0.95       285\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 98   8]\n",
      " [  7 172]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.03176558417319908), 'test_error': 0.052631578947368474, 'best_params': {'max_depth': None, 'n_estimators': 50}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.9626 (Error: 0.0374)\n",
      "Testing Accuracy: 0.9474 (Error: 0.0526)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        42\n",
      "           1       0.96      0.96      0.96        72\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39  3]\n",
      " [ 3 69]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.03736784013012662), 'test_error': 0.052631578947368474, 'best_params': {'max_depth': None, 'n_estimators': 200}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "        print(f\"\\n--- Results for {partition} Split ---\")\n",
    "        result = evaluate_classifier(rf, params, X_train, X_test, y_train, y_test)\n",
    "        print(result)\n",
    "        #results[dataset_name][partition][clf_name] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938a1c3",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616fcd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dt = {\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d2fd455",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70fb86",
   "metadata": {},
   "source": [
    "### Getting Accuracy reports for our different training/test split for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c52918d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.9471 (Error: 0.0529)\n",
      "Testing Accuracy: 0.8794 (Error: 0.1206)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82       170\n",
      "           1       0.87      0.95      0.91       286\n",
      "\n",
      "    accuracy                           0.88       456\n",
      "   macro avg       0.89      0.85      0.87       456\n",
      "weighted avg       0.88      0.88      0.88       456\n",
      "\n",
      "Confusion Matrix:\n",
      "[[129  41]\n",
      " [ 14 272]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.05286865813181618), 'test_error': 0.12061403508771928, 'best_params': {'max_depth': None, 'min_samples_split': 2}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'max_depth': 20, 'min_samples_split': 2}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.9471 (Error: 0.0529)\n",
      "Testing Accuracy: 0.9123 (Error: 0.0877)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       106\n",
      "           1       0.94      0.92      0.93       179\n",
      "\n",
      "    accuracy                           0.91       285\n",
      "   macro avg       0.90      0.91      0.91       285\n",
      "weighted avg       0.91      0.91      0.91       285\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 95  11]\n",
      " [ 14 165]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.05285554311310181), 'test_error': 0.08771929824561409, 'best_params': {'max_depth': 20, 'min_samples_split': 2}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'max_depth': 20, 'min_samples_split': 5}\n",
      "Training Accuracy: 0.9956 (Error: 0.0044)\n",
      "Validation Accuracy: 0.9275 (Error: 0.0725)\n",
      "Testing Accuracy: 0.9123 (Error: 0.0877)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89        42\n",
      "           1       0.96      0.90      0.93        72\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.92      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39  3]\n",
      " [ 7 65]]\n",
      "{'train_error': 0.00439560439560438, 'validation_error': np.float64(0.07252817474148943), 'test_error': 0.08771929824561409, 'best_params': {'max_depth': 20, 'min_samples_split': 5}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(dt, params_dt, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16823f56",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a83f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_knn = {\n",
    "        \"n_neighbors\": [3, 5, 10],\n",
    "        \"weights\": [\"uniform\", \"distance\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3687ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2632fa4",
   "metadata": {},
   "source": [
    "### Getting Accuracy reports for our different training/test split for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "556657a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Training Accuracy: 0.9115 (Error: 0.0885)\n",
      "Validation Accuracy: 0.9203 (Error: 0.0797)\n",
      "Testing Accuracy: 0.9101 (Error: 0.0899)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.79      0.87       170\n",
      "           1       0.89      0.98      0.93       286\n",
      "\n",
      "    accuracy                           0.91       456\n",
      "   macro avg       0.92      0.89      0.90       456\n",
      "weighted avg       0.91      0.91      0.91       456\n",
      "\n",
      "Confusion Matrix:\n",
      "[[135  35]\n",
      " [  6 280]]\n",
      "{'train_error': 0.08849557522123896, 'validation_error': np.float64(0.07965860597439545), 'test_error': 0.08991228070175439, 'best_params': {'n_neighbors': 3, 'weights': 'uniform'}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.9367 (Error: 0.0633)\n",
      "Testing Accuracy: 0.9333 (Error: 0.0667)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       106\n",
      "           1       0.93      0.96      0.95       179\n",
      "\n",
      "    accuracy                           0.93       285\n",
      "   macro avg       0.93      0.92      0.93       285\n",
      "weighted avg       0.93      0.93      0.93       285\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 94  12]\n",
      " [  7 172]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.06334453154162001), 'test_error': 0.06666666666666665, 'best_params': {'n_neighbors': 5, 'weights': 'distance'}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Training Accuracy: 0.9473 (Error: 0.0527)\n",
      "Validation Accuracy: 0.9494 (Error: 0.0506)\n",
      "Testing Accuracy: 0.9123 (Error: 0.0877)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        42\n",
      "           1       0.94      0.92      0.93        72\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.91      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[38  4]\n",
      " [ 6 66]]\n",
      "{'train_error': 0.05274725274725278, 'validation_error': np.float64(0.050554780992215775), 'test_error': 0.08771929824561409, 'best_params': {'n_neighbors': 5, 'weights': 'uniform'}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "        print(f\"\\n--- Results for {partition} Split ---\")\n",
    "        result = evaluate_classifier(knn, params_knn, X_train, X_test, y_train, y_test)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b579086",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f06bc",
   "metadata": {},
   "source": [
    "### Getting Accuracy reports for our different training/test split for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34ae2a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'var_smoothing': 1e-07}\n",
      "Training Accuracy: 0.9558 (Error: 0.0442)\n",
      "Validation Accuracy: 0.9467 (Error: 0.0533)\n",
      "Testing Accuracy: 0.9167 (Error: 0.0833)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88       170\n",
      "           1       0.89      0.99      0.94       286\n",
      "\n",
      "    accuracy                           0.92       456\n",
      "   macro avg       0.94      0.89      0.91       456\n",
      "weighted avg       0.92      0.92      0.91       456\n",
      "\n",
      "Confusion Matrix:\n",
      "[[134  36]\n",
      " [  2 284]]\n",
      "{'train_error': 0.04424778761061943, 'validation_error': np.float64(0.053342816500711265), 'test_error': 0.08333333333333337, 'best_params': {'var_smoothing': 1e-07}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'var_smoothing': 1e-09}\n",
      "Training Accuracy: 0.9401 (Error: 0.0599)\n",
      "Validation Accuracy: 0.9365 (Error: 0.0635)\n",
      "Testing Accuracy: 0.9439 (Error: 0.0561)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92       106\n",
      "           1       0.93      0.98      0.96       179\n",
      "\n",
      "    accuracy                           0.94       285\n",
      "   macro avg       0.95      0.93      0.94       285\n",
      "weighted avg       0.95      0.94      0.94       285\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 93  13]\n",
      " [  3 176]]\n",
      "{'train_error': 0.059859154929577496, 'validation_error': np.float64(0.06353116834639794), 'test_error': 0.056140350877192935, 'best_params': {'var_smoothing': 1e-09}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'var_smoothing': 1e-09}\n",
      "Training Accuracy: 0.9407 (Error: 0.0593)\n",
      "Validation Accuracy: 0.9385 (Error: 0.0615)\n",
      "Testing Accuracy: 0.9386 (Error: 0.0614)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92        42\n",
      "           1       0.95      0.96      0.95        72\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[38  4]\n",
      " [ 3 69]]\n",
      "{'train_error': 0.05934065934065935, 'validation_error': np.float64(0.0615342163355409), 'test_error': 0.06140350877192979, 'best_params': {'var_smoothing': 1e-09}}\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for GaussianNB\n",
    "naive_bayes_params = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7]  # Smoothing parameter for GaussianNB\n",
    "}\n",
    "\n",
    "# Run evaluation\n",
    "for partition, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(GaussianNB(), naive_bayes_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189d65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1adc2f95",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae25cb1e",
   "metadata": {},
   "source": [
    "### Getting Accuracy reports for our different training/test split for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3480143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'svm__C': 0.1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Training Accuracy: 0.9912 (Error: 0.0088)\n",
      "Validation Accuracy: 0.9822 (Error: 0.0178)\n",
      "Testing Accuracy: 0.9605 (Error: 0.0395)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.94       170\n",
      "           1       0.95      0.99      0.97       286\n",
      "\n",
      "    accuracy                           0.96       456\n",
      "   macro avg       0.97      0.95      0.96       456\n",
      "weighted avg       0.96      0.96      0.96       456\n",
      "\n",
      "Confusion Matrix:\n",
      "[[154  16]\n",
      " [  2 284]]\n",
      "{'train_error': 0.008849557522123908, 'validation_error': np.float64(0.01778093883357046), 'test_error': 0.03947368421052633, 'best_params': {'svm__C': 0.1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'svm__C': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Training Accuracy: 0.9930 (Error: 0.0070)\n",
      "Validation Accuracy: 0.9789 (Error: 0.0211)\n",
      "Testing Accuracy: 0.9719 (Error: 0.0281)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       106\n",
      "           1       0.98      0.98      0.98       179\n",
      "\n",
      "    accuracy                           0.97       285\n",
      "   macro avg       0.97      0.97      0.97       285\n",
      "weighted avg       0.97      0.97      0.97       285\n",
      "\n",
      "Confusion Matrix:\n",
      "[[102   4]\n",
      " [  4 175]]\n",
      "{'train_error': 0.007042253521126751, 'validation_error': np.float64(0.021127286300858583), 'test_error': 0.028070175438596467, 'best_params': {'svm__C': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'svm__C': 0.1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Training Accuracy: 0.9846 (Error: 0.0154)\n",
      "Validation Accuracy: 0.9781 (Error: 0.0219)\n",
      "Testing Accuracy: 0.9825 (Error: 0.0175)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        42\n",
      "           1       0.99      0.99      0.99        72\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41  1]\n",
      " [ 1 71]]\n",
      "{'train_error': 0.01538461538461533, 'validation_error': np.float64(0.02194434762402686), 'test_error': 0.01754385964912286, 'best_params': {'svm__C': 0.1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "# Define a pipeline with scaling and SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(probability=True))  # Set probability=True to enable ROC-AUC computation\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "svm_params = {\n",
    "    \"svm__C\": [0.1, 1, 10],        # Regularization strength\n",
    "    \"svm__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"svm__gamma\": [\"scale\", \"auto\"]  # Kernel coefficient for rbf\n",
    "}\n",
    "\n",
    "# Run evaluation\n",
    "for partition, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(svm_pipeline, svm_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830756af",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a0619",
   "metadata": {},
   "source": [
    "### Getting Accuracy reports for our different training/test split for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5851baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'C': 0.1, 'max_iter': 7000}\n",
      "Training Accuracy: 0.9646 (Error: 0.0354)\n",
      "Validation Accuracy: 0.9559 (Error: 0.0441)\n",
      "Testing Accuracy: 0.9320 (Error: 0.0680)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90       170\n",
      "           1       0.92      0.98      0.95       286\n",
      "\n",
      "    accuracy                           0.93       456\n",
      "   macro avg       0.94      0.91      0.93       456\n",
      "weighted avg       0.93      0.93      0.93       456\n",
      "\n",
      "Confusion Matrix:\n",
      "[[144  26]\n",
      " [  5 281]]\n",
      "{'train_error': 0.03539823008849563, 'validation_error': np.float64(0.04409672830725453), 'test_error': 0.06798245614035092, 'best_params': {'C': 0.1, 'max_iter': 7000}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'C': 10, 'max_iter': 7000}\n",
      "Training Accuracy: 0.9859 (Error: 0.0141)\n",
      "Validation Accuracy: 0.9648 (Error: 0.0352)\n",
      "Testing Accuracy: 0.9579 (Error: 0.0421)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       106\n",
      "           1       0.95      0.98      0.97       179\n",
      "\n",
      "    accuracy                           0.96       285\n",
      "   macro avg       0.96      0.95      0.95       285\n",
      "weighted avg       0.96      0.96      0.96       285\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 97   9]\n",
      " [  3 176]]\n",
      "{'train_error': 0.014084507042253502, 'validation_error': np.float64(0.03523702874206791), 'test_error': 0.04210526315789476, 'best_params': {'C': 10, 'max_iter': 7000}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'C': 10, 'max_iter': 7000}\n",
      "Training Accuracy: 0.9692 (Error: 0.0308)\n",
      "Validation Accuracy: 0.9561 (Error: 0.0439)\n",
      "Testing Accuracy: 0.9649 (Error: 0.0351)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        42\n",
      "           1       0.96      0.99      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39  3]\n",
      " [ 1 71]]\n",
      "{'train_error': 0.03076923076923077, 'validation_error': np.float64(0.043946787498547635), 'test_error': 0.03508771929824561, 'best_params': {'C': 10, 'max_iter': 7000}}\n"
     ]
    }
   ],
   "source": [
    "logistic_reg_params = {\"C\": [0.1, 1, 10], \"max_iter\": [7000, 10000]}\n",
    "\n",
    "for partition, (X_train, X_test, y_train, y_test) in splits.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(LogisticRegression(), logistic_reg_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de6afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0116a799",
   "metadata": {},
   "source": [
    "# Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "678757f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "#adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "#X = adult.data.features \n",
    "#y = adult.data.targets \n",
    "  \n",
    "# metadata \n",
    "#print(adult.metadata) \n",
    "  \n",
    "# variable information \n",
    "#adult.variables\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "288def0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('heart_disease_uci.csv')\n",
    "#data2.dropna(inplace=True)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a982f9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca               thal  \n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0       fixed defect  \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0             normal  \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0  reversable defect  \n",
       "3          normal   187.0  False      3.5  downsloping  0.0             normal  \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0             normal  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data2.drop(columns = ['num', 'id'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "774c9ecb-504b-42e4-b1ad-da5d1d036ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_columns = [\n",
    "    'sex', 'dataset', 'cp',\n",
    "    'fbs', 'restecg','exang', 'slope','thal'\n",
    "]\n",
    "numerical_columns = [\n",
    "    'age','trestbps', 'chol', \n",
    "    'thalch', 'oldpeak', 'ca'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30c38a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(X):\n",
    "    # Fill missing values in numerical columns with the mean\n",
    "    X[numerical_columns] = X[numerical_columns].fillna(X[numerical_columns].mean())\n",
    "\n",
    "    # Fill missing values in categorical columns with the mode\n",
    "    X[categorical_columns] = X[categorical_columns].fillna(X[categorical_columns].mode().iloc[0])\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c00f710-5573-4f84-a19c-a06a4ca8dd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rkhus\\AppData\\Local\\Temp\\ipykernel_2164\\2827648026.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[categorical_columns] = X[categorical_columns].fillna(X[categorical_columns].mode().iloc[0])\n"
     ]
    }
   ],
   "source": [
    "X = handle_missing_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22e826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f752cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Create the preprocessing transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_columns),\n",
    "         ('num', StandardScaler(), numerical_columns)\n",
    "    ])\n",
    "\n",
    "def preprocess_data(X):\n",
    "    # Fit and transform the entire dataset\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Get feature names for numerical and categorical columns\n",
    "    num_feature_names = numerical_columns\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns)\n",
    "\n",
    "    # Combine feature names\n",
    "    feature_names = list(num_feature_names) + list(cat_feature_names)\n",
    "\n",
    "    # Create a DataFrame from the transformed array\n",
    "    X_transformed_df = pd.DataFrame(\n",
    "        X_transformed, \n",
    "        columns=feature_names, \n",
    "        index=X.index  # Preserve the original index\n",
    "    )\n",
    "\n",
    "    return X_transformed_df\n",
    "\n",
    "# Optional: If you want to keep numerical columns as well\n",
    "def preprocess_data_full(X):\n",
    "    # Fit and transform the data\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Get feature names for numerical and categorical columns\n",
    "    num_feature_names = numerical_columns\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns)\n",
    "\n",
    "    # Combine feature names\n",
    "    feature_names = list(num_feature_names) + list(cat_feature_names)\n",
    "\n",
    "    # Create a DataFrame from the transformed array\n",
    "    X_transformed_df = pd.DataFrame(\n",
    "        X_transformed, \n",
    "        columns=feature_names, \n",
    "        index=X.index  # Preserve the original index\n",
    "    )\n",
    "\n",
    "    return X_transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3e17a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalch</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>dataset_Cleveland</th>\n",
       "      <th>dataset_Hungary</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_normal</th>\n",
       "      <th>restecg_st-t abnormality</th>\n",
       "      <th>exang_False</th>\n",
       "      <th>exang_True</th>\n",
       "      <th>slope_downsloping</th>\n",
       "      <th>slope_flat</th>\n",
       "      <th>slope_upsloping</th>\n",
       "      <th>thal_fixed defect</th>\n",
       "      <th>thal_normal</th>\n",
       "      <th>thal_reversable defect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.007386</td>\n",
       "      <td>0.698041</td>\n",
       "      <td>0.311021</td>\n",
       "      <td>0.495698</td>\n",
       "      <td>1.349421</td>\n",
       "      <td>-1.249371e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.432034</td>\n",
       "      <td>1.511761</td>\n",
       "      <td>0.797713</td>\n",
       "      <td>-1.175955</td>\n",
       "      <td>0.589832</td>\n",
       "      <td>4.292099e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.432034</td>\n",
       "      <td>-0.658158</td>\n",
       "      <td>0.274289</td>\n",
       "      <td>-0.340128</td>\n",
       "      <td>1.634267</td>\n",
       "      <td>2.444942e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.752828</td>\n",
       "      <td>-0.115679</td>\n",
       "      <td>0.467130</td>\n",
       "      <td>1.968345</td>\n",
       "      <td>2.488805</td>\n",
       "      <td>-1.249371e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.328180</td>\n",
       "      <td>-0.115679</td>\n",
       "      <td>0.044717</td>\n",
       "      <td>1.371326</td>\n",
       "      <td>0.494884</td>\n",
       "      <td>-1.249371e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051927</td>\n",
       "      <td>-0.278423</td>\n",
       "      <td>1.229308</td>\n",
       "      <td>0.654903</td>\n",
       "      <td>-0.834397</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.552169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158089</td>\n",
       "      <td>-0.549662</td>\n",
       "      <td>0.219192</td>\n",
       "      <td>-1.494365</td>\n",
       "      <td>-0.834397</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.706817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901224</td>\n",
       "      <td>-0.658158</td>\n",
       "      <td>0.503861</td>\n",
       "      <td>-1.772974</td>\n",
       "      <td>-0.834397</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  trestbps  chol  thalch  oldpeak   ca  sex_Female  sex_Male  \\\n",
       "0    0.0       1.0   1.0     0.0      0.0  0.0         0.0       0.0   \n",
       "1    0.0       1.0   1.0     0.0      0.0  0.0         1.0       0.0   \n",
       "2    0.0       1.0   1.0     0.0      0.0  0.0         1.0       0.0   \n",
       "3    0.0       1.0   1.0     0.0      0.0  0.0         0.0       0.0   \n",
       "4    1.0       0.0   1.0     0.0      0.0  0.0         0.0       1.0   \n",
       "..   ...       ...   ...     ...      ...  ...         ...       ...   \n",
       "915  1.0       0.0   0.0     0.0      0.0  1.0         1.0       0.0   \n",
       "916  0.0       1.0   0.0     0.0      0.0  1.0         0.0       0.0   \n",
       "917  0.0       1.0   0.0     0.0      0.0  1.0         1.0       0.0   \n",
       "918  0.0       1.0   0.0     0.0      0.0  1.0         1.0       0.0   \n",
       "919  0.0       1.0   0.0     0.0      0.0  1.0         0.0       1.0   \n",
       "\n",
       "     dataset_Cleveland  dataset_Hungary  ...  restecg_normal  \\\n",
       "0                  0.0              1.0  ...             0.0   \n",
       "1                  0.0              0.0  ...             0.0   \n",
       "2                  0.0              0.0  ...             0.0   \n",
       "3                  1.0              0.0  ...             0.0   \n",
       "4                  0.0              0.0  ...             1.0   \n",
       "..                 ...              ...  ...             ...   \n",
       "915                0.0              0.0  ...             0.0   \n",
       "916                0.0              1.0  ...             0.0   \n",
       "917                0.0              0.0  ...             0.0   \n",
       "918                0.0              0.0  ...             0.0   \n",
       "919                0.0              0.0  ...             0.0   \n",
       "\n",
       "     restecg_st-t abnormality  exang_False  exang_True  slope_downsloping  \\\n",
       "0                         1.0          0.0         0.0           1.007386   \n",
       "1                         0.0          1.0         0.0           1.432034   \n",
       "2                         0.0          0.0         1.0           1.432034   \n",
       "3                         0.0          1.0         0.0          -1.752828   \n",
       "4                         0.0          1.0         0.0          -1.328180   \n",
       "..                        ...          ...         ...                ...   \n",
       "915                       0.0          1.0         0.0           0.051927   \n",
       "916                       0.0          1.0         0.0           0.901224   \n",
       "917                       1.0          0.0         0.0           0.158089   \n",
       "918                       0.0          1.0         0.0           0.476575   \n",
       "919                       0.0          1.0         0.0           0.901224   \n",
       "\n",
       "     slope_flat  slope_upsloping  thal_fixed defect  thal_normal  \\\n",
       "0      0.698041         0.311021           0.495698     1.349421   \n",
       "1      1.511761         0.797713          -1.175955     0.589832   \n",
       "2     -0.658158         0.274289          -0.340128     1.634267   \n",
       "3     -0.115679         0.467130           1.968345     2.488805   \n",
       "4     -0.115679         0.044717           1.371326     0.494884   \n",
       "..          ...              ...                ...          ...   \n",
       "915   -0.278423         1.229308           0.654903    -0.834397   \n",
       "916    0.000000        -0.552169           0.000000     0.000000   \n",
       "917   -0.549662         0.219192          -1.494365    -0.834397   \n",
       "918    0.000000         1.706817           0.000000     0.000000   \n",
       "919   -0.658158         0.503861          -1.772974    -0.834397   \n",
       "\n",
       "     thal_reversable defect  \n",
       "0             -1.249371e+00  \n",
       "1              4.292099e+00  \n",
       "2              2.444942e+00  \n",
       "3             -1.249371e+00  \n",
       "4             -1.249371e+00  \n",
       "..                      ...  \n",
       "915           -2.050756e-16  \n",
       "916           -2.050756e-16  \n",
       "917           -2.050756e-16  \n",
       "918           -2.050756e-16  \n",
       "919           -2.050756e-16  \n",
       "\n",
       "[920 rows x 29 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocess_data_full(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9c4e044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalch</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>dataset_Cleveland</th>\n",
       "      <th>dataset_Hungary</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_normal</th>\n",
       "      <th>restecg_st-t abnormality</th>\n",
       "      <th>exang_False</th>\n",
       "      <th>exang_True</th>\n",
       "      <th>slope_downsloping</th>\n",
       "      <th>slope_flat</th>\n",
       "      <th>slope_upsloping</th>\n",
       "      <th>thal_fixed defect</th>\n",
       "      <th>thal_normal</th>\n",
       "      <th>thal_reversable defect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.007386</td>\n",
       "      <td>0.698041</td>\n",
       "      <td>0.311021</td>\n",
       "      <td>0.495698</td>\n",
       "      <td>1.349421</td>\n",
       "      <td>-1.249371e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.432034</td>\n",
       "      <td>1.511761</td>\n",
       "      <td>0.797713</td>\n",
       "      <td>-1.175955</td>\n",
       "      <td>0.589832</td>\n",
       "      <td>4.292099e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.432034</td>\n",
       "      <td>-0.658158</td>\n",
       "      <td>0.274289</td>\n",
       "      <td>-0.340128</td>\n",
       "      <td>1.634267</td>\n",
       "      <td>2.444942e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.752828</td>\n",
       "      <td>-0.115679</td>\n",
       "      <td>0.467130</td>\n",
       "      <td>1.968345</td>\n",
       "      <td>2.488805</td>\n",
       "      <td>-1.249371e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.328180</td>\n",
       "      <td>-0.115679</td>\n",
       "      <td>0.044717</td>\n",
       "      <td>1.371326</td>\n",
       "      <td>0.494884</td>\n",
       "      <td>-1.249371e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051927</td>\n",
       "      <td>-0.278423</td>\n",
       "      <td>1.229308</td>\n",
       "      <td>0.654903</td>\n",
       "      <td>-0.834397</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.552169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158089</td>\n",
       "      <td>-0.549662</td>\n",
       "      <td>0.219192</td>\n",
       "      <td>-1.494365</td>\n",
       "      <td>-0.834397</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.706817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901224</td>\n",
       "      <td>-0.658158</td>\n",
       "      <td>0.503861</td>\n",
       "      <td>-1.772974</td>\n",
       "      <td>-0.834397</td>\n",
       "      <td>-2.050756e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  trestbps  chol  thalch  oldpeak   ca  sex_Female  sex_Male  \\\n",
       "0    0.0       1.0   1.0     0.0      0.0  0.0         0.0       0.0   \n",
       "1    0.0       1.0   1.0     0.0      0.0  0.0         1.0       0.0   \n",
       "2    0.0       1.0   1.0     0.0      0.0  0.0         1.0       0.0   \n",
       "3    0.0       1.0   1.0     0.0      0.0  0.0         0.0       0.0   \n",
       "4    1.0       0.0   1.0     0.0      0.0  0.0         0.0       1.0   \n",
       "..   ...       ...   ...     ...      ...  ...         ...       ...   \n",
       "915  1.0       0.0   0.0     0.0      0.0  1.0         1.0       0.0   \n",
       "916  0.0       1.0   0.0     0.0      0.0  1.0         0.0       0.0   \n",
       "917  0.0       1.0   0.0     0.0      0.0  1.0         1.0       0.0   \n",
       "918  0.0       1.0   0.0     0.0      0.0  1.0         1.0       0.0   \n",
       "919  0.0       1.0   0.0     0.0      0.0  1.0         0.0       1.0   \n",
       "\n",
       "     dataset_Cleveland  dataset_Hungary  ...  restecg_normal  \\\n",
       "0                  0.0              1.0  ...             0.0   \n",
       "1                  0.0              0.0  ...             0.0   \n",
       "2                  0.0              0.0  ...             0.0   \n",
       "3                  1.0              0.0  ...             0.0   \n",
       "4                  0.0              0.0  ...             1.0   \n",
       "..                 ...              ...  ...             ...   \n",
       "915                0.0              0.0  ...             0.0   \n",
       "916                0.0              1.0  ...             0.0   \n",
       "917                0.0              0.0  ...             0.0   \n",
       "918                0.0              0.0  ...             0.0   \n",
       "919                0.0              0.0  ...             0.0   \n",
       "\n",
       "     restecg_st-t abnormality  exang_False  exang_True  slope_downsloping  \\\n",
       "0                         1.0          0.0         0.0           1.007386   \n",
       "1                         0.0          1.0         0.0           1.432034   \n",
       "2                         0.0          0.0         1.0           1.432034   \n",
       "3                         0.0          1.0         0.0          -1.752828   \n",
       "4                         0.0          1.0         0.0          -1.328180   \n",
       "..                        ...          ...         ...                ...   \n",
       "915                       0.0          1.0         0.0           0.051927   \n",
       "916                       0.0          1.0         0.0           0.901224   \n",
       "917                       1.0          0.0         0.0           0.158089   \n",
       "918                       0.0          1.0         0.0           0.476575   \n",
       "919                       0.0          1.0         0.0           0.901224   \n",
       "\n",
       "     slope_flat  slope_upsloping  thal_fixed defect  thal_normal  \\\n",
       "0      0.698041         0.311021           0.495698     1.349421   \n",
       "1      1.511761         0.797713          -1.175955     0.589832   \n",
       "2     -0.658158         0.274289          -0.340128     1.634267   \n",
       "3     -0.115679         0.467130           1.968345     2.488805   \n",
       "4     -0.115679         0.044717           1.371326     0.494884   \n",
       "..          ...              ...                ...          ...   \n",
       "915   -0.278423         1.229308           0.654903    -0.834397   \n",
       "916    0.000000        -0.552169           0.000000     0.000000   \n",
       "917   -0.549662         0.219192          -1.494365    -0.834397   \n",
       "918    0.000000         1.706817           0.000000     0.000000   \n",
       "919   -0.658158         0.503861          -1.772974    -0.834397   \n",
       "\n",
       "     thal_reversable defect  \n",
       "0             -1.249371e+00  \n",
       "1              4.292099e+00  \n",
       "2              2.444942e+00  \n",
       "3             -1.249371e+00  \n",
       "4             -1.249371e+00  \n",
       "..                      ...  \n",
       "915           -2.050756e-16  \n",
       "916           -2.050756e-16  \n",
       "917           -2.050756e-16  \n",
       "918           -2.050756e-16  \n",
       "919           -2.050756e-16  \n",
       "\n",
       "[920 rows x 29 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d91e83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>920 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num\n",
       "0      0\n",
       "1      2\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "..   ...\n",
       "915    1\n",
       "916    0\n",
       "917    2\n",
       "918    0\n",
       "919    1\n",
       "\n",
       "[920 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data2[['num']]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ccfb3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>num_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num  num_binary\n",
       "0    0           0\n",
       "1    2           1\n",
       "2    1           1\n",
       "3    0           0\n",
       "4    0           0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.assign(num_binary=y['num'].apply(lambda x: 0 if x == 0 else 1))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02b14ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "915    1\n",
       "916    0\n",
       "917    1\n",
       "918    0\n",
       "919    1\n",
       "Name: num_binary, Length: 920, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y['num_binary']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d011f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dabf1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_d2 = {\n",
    "        \"20/80\": stratified_split_data(X, y, test_size=0.8),\n",
    "        \"50/50\": stratified_split_data(X, y, test_size=0.5),\n",
    "        \"80/20\": stratified_split_data(X, y, test_size=0.2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2da21",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "566566cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'max_depth': 20, 'n_estimators': 100}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.8262 (Error: 0.1738)\n",
      "Testing Accuracy: 0.8302 (Error: 0.1698)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       329\n",
      "           1       0.83      0.87      0.85       407\n",
      "\n",
      "    accuracy                           0.83       736\n",
      "   macro avg       0.83      0.82      0.83       736\n",
      "weighted avg       0.83      0.83      0.83       736\n",
      "\n",
      "Confusion Matrix:\n",
      "[[255  74]\n",
      " [ 51 356]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.17380574651859693), 'test_error': 0.16983695652173914, 'best_params': {'max_depth': 20, 'n_estimators': 100}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 50}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.8152 (Error: 0.1848)\n",
      "Testing Accuracy: 0.8304 (Error: 0.1696)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       206\n",
      "           1       0.86      0.83      0.84       254\n",
      "\n",
      "    accuracy                           0.83       460\n",
      "   macro avg       0.83      0.83      0.83       460\n",
      "weighted avg       0.83      0.83      0.83       460\n",
      "\n",
      "Confusion Matrix:\n",
      "[[172  34]\n",
      " [ 44 210]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.18480321421497903), 'test_error': 0.16956521739130437, 'best_params': {'max_depth': None, 'n_estimators': 50}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'max_depth': None, 'n_estimators': 50}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.8261 (Error: 0.1739)\n",
      "Testing Accuracy: 0.8370 (Error: 0.1630)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.78      0.81        82\n",
      "           1       0.83      0.88      0.86       102\n",
      "\n",
      "    accuracy                           0.84       184\n",
      "   macro avg       0.84      0.83      0.83       184\n",
      "weighted avg       0.84      0.84      0.84       184\n",
      "\n",
      "Confusion Matrix:\n",
      "[[64 18]\n",
      " [12 90]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.17393396382943427), 'test_error': 0.1630434782608695, 'best_params': {'max_depth': None, 'n_estimators': 50}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d2.items():\n",
    "        print(f\"\\n--- Results for {partition} Split ---\")\n",
    "        result = evaluate_classifier(rf, params, X_train, X_test, y_train, y_test)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818df3d5",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91a7c5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 10}\n",
      "Training Accuracy: 0.9348 (Error: 0.0652)\n",
      "Validation Accuracy: 0.7664 (Error: 0.2336)\n",
      "Testing Accuracy: 0.7962 (Error: 0.2038)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76       329\n",
      "           1       0.80      0.85      0.82       407\n",
      "\n",
      "    accuracy                           0.80       736\n",
      "   macro avg       0.80      0.79      0.79       736\n",
      "weighted avg       0.80      0.80      0.80       736\n",
      "\n",
      "Confusion Matrix:\n",
      "[[241  88]\n",
      " [ 62 345]]\n",
      "{'train_error': 0.06521739130434778, 'validation_error': np.float64(0.23356248898290144), 'test_error': 0.20380434782608692, 'best_params': {'max_depth': None, 'min_samples_split': 10}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'max_depth': 20, 'min_samples_split': 10}\n",
      "Training Accuracy: 0.9130 (Error: 0.0870)\n",
      "Validation Accuracy: 0.7304 (Error: 0.2696)\n",
      "Testing Accuracy: 0.7500 (Error: 0.2500)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73       206\n",
      "           1       0.80      0.74      0.76       254\n",
      "\n",
      "    accuracy                           0.75       460\n",
      "   macro avg       0.75      0.75      0.75       460\n",
      "weighted avg       0.75      0.75      0.75       460\n",
      "\n",
      "Confusion Matrix:\n",
      "[[158  48]\n",
      " [ 67 187]]\n",
      "{'train_error': 0.08695652173913049, 'validation_error': np.float64(0.26957247545482843), 'test_error': 0.25, 'best_params': {'max_depth': 20, 'min_samples_split': 10}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 5}\n",
      "Training Accuracy: 0.9524 (Error: 0.0476)\n",
      "Validation Accuracy: 0.7336 (Error: 0.2664)\n",
      "Testing Accuracy: 0.7717 (Error: 0.2283)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73        82\n",
      "           1       0.78      0.82      0.80       102\n",
      "\n",
      "    accuracy                           0.77       184\n",
      "   macro avg       0.77      0.77      0.77       184\n",
      "weighted avg       0.77      0.77      0.77       184\n",
      "\n",
      "Confusion Matrix:\n",
      "[[58 24]\n",
      " [18 84]]\n",
      "{'train_error': 0.04755434782608692, 'validation_error': np.float64(0.2663624799513302), 'test_error': 0.2282608695652174, 'best_params': {'max_depth': 10, 'min_samples_split': 5}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d2.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(dt, params_dt, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15b746",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70629a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6b33222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Training Accuracy: 0.8804 (Error: 0.1196)\n",
      "Validation Accuracy: 0.8317 (Error: 0.1683)\n",
      "Testing Accuracy: 0.8166 (Error: 0.1834)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79       329\n",
      "           1       0.81      0.87      0.84       407\n",
      "\n",
      "    accuracy                           0.82       736\n",
      "   macro avg       0.82      0.81      0.81       736\n",
      "weighted avg       0.82      0.82      0.82       736\n",
      "\n",
      "Confusion Matrix:\n",
      "[[247  82]\n",
      " [ 53 354]]\n",
      "{'train_error': 0.11956521739130432, 'validation_error': np.float64(0.16834126564427987), 'test_error': 0.18342391304347827, 'best_params': {'n_neighbors': 5, 'weights': 'uniform'}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'n_neighbors': 10, 'weights': 'distance'}\n",
      "Training Accuracy: 1.0000 (Error: 0.0000)\n",
      "Validation Accuracy: 0.8391 (Error: 0.1609)\n",
      "Testing Accuracy: 0.8326 (Error: 0.1674)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       206\n",
      "           1       0.85      0.85      0.85       254\n",
      "\n",
      "    accuracy                           0.83       460\n",
      "   macro avg       0.83      0.83      0.83       460\n",
      "weighted avg       0.83      0.83      0.83       460\n",
      "\n",
      "Confusion Matrix:\n",
      "[[167  39]\n",
      " [ 38 216]]\n",
      "{'train_error': 0.0, 'validation_error': np.float64(0.16086636674871968), 'test_error': 0.16739130434782612, 'best_params': {'n_neighbors': 10, 'weights': 'distance'}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Training Accuracy: 0.8682 (Error: 0.1318)\n",
      "Validation Accuracy: 0.8220 (Error: 0.1780)\n",
      "Testing Accuracy: 0.8315 (Error: 0.1685)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80        82\n",
      "           1       0.82      0.89      0.85       102\n",
      "\n",
      "    accuracy                           0.83       184\n",
      "   macro avg       0.83      0.82      0.83       184\n",
      "weighted avg       0.83      0.83      0.83       184\n",
      "\n",
      "Confusion Matrix:\n",
      "[[62 20]\n",
      " [11 91]]\n",
      "{'train_error': 0.1317934782608695, 'validation_error': np.float64(0.17803218848515012), 'test_error': 0.1684782608695652, 'best_params': {'n_neighbors': 5, 'weights': 'uniform'}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d2.items():\n",
    "        print(f\"\\n--- Results for {partition} Split ---\")\n",
    "        result = evaluate_classifier(knn, params_knn, X_train, X_test, y_train, y_test)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46350ae1",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8531d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'var_smoothing': 1e-07}\n",
      "Training Accuracy: 0.7500 (Error: 0.2500)\n",
      "Validation Accuracy: 0.7173 (Error: 0.2827)\n",
      "Testing Accuracy: 0.7649 (Error: 0.2351)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78       329\n",
      "           1       0.90      0.65      0.75       407\n",
      "\n",
      "    accuracy                           0.76       736\n",
      "   macro avg       0.79      0.78      0.76       736\n",
      "weighted avg       0.80      0.76      0.76       736\n",
      "\n",
      "Confusion Matrix:\n",
      "[[300  29]\n",
      " [144 263]]\n",
      "{'train_error': 0.25, 'validation_error': np.float64(0.28274281685175395), 'test_error': 0.23505434782608692, 'best_params': {'var_smoothing': 1e-07}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'var_smoothing': 1e-09}\n",
      "Training Accuracy: 0.8109 (Error: 0.1891)\n",
      "Validation Accuracy: 0.7979 (Error: 0.2021)\n",
      "Testing Accuracy: 0.8196 (Error: 0.1804)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       206\n",
      "           1       0.86      0.80      0.83       254\n",
      "\n",
      "    accuracy                           0.82       460\n",
      "   macro avg       0.82      0.82      0.82       460\n",
      "weighted avg       0.82      0.82      0.82       460\n",
      "\n",
      "Confusion Matrix:\n",
      "[[173  33]\n",
      " [ 50 204]]\n",
      "{'train_error': 0.18913043478260871, 'validation_error': np.float64(0.20209093738505501), 'test_error': 0.1804347826086956, 'best_params': {'var_smoothing': 1e-09}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'var_smoothing': 1e-09}\n",
      "Training Accuracy: 0.8152 (Error: 0.1848)\n",
      "Validation Accuracy: 0.8138 (Error: 0.1862)\n",
      "Testing Accuracy: 0.8750 (Error: 0.1250)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86        82\n",
      "           1       0.88      0.90      0.89       102\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.87      0.87      0.87       184\n",
      "weighted avg       0.87      0.88      0.87       184\n",
      "\n",
      "Confusion Matrix:\n",
      "[[69 13]\n",
      " [10 92]]\n",
      "{'train_error': 0.18478260869565222, 'validation_error': np.float64(0.18615120845085997), 'test_error': 0.125, 'best_params': {'var_smoothing': 1e-09}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d2.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(GaussianNB(), naive_bayes_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d2bf7",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06781b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "Training Accuracy: 0.9783 (Error: 0.0217)\n",
      "Validation Accuracy: 0.8099 (Error: 0.1901)\n",
      "Testing Accuracy: 0.8057 (Error: 0.1943)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       329\n",
      "           1       0.80      0.87      0.83       407\n",
      "\n",
      "    accuracy                           0.81       736\n",
      "   macro avg       0.81      0.80      0.80       736\n",
      "weighted avg       0.81      0.81      0.80       736\n",
      "\n",
      "Confusion Matrix:\n",
      "[[240  89]\n",
      " [ 54 353]]\n",
      "{'train_error': 0.021739130434782594, 'validation_error': np.float64(0.19011105235325232), 'test_error': 0.1942934782608695, 'best_params': {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}\n",
      "Training Accuracy: 0.9674 (Error: 0.0326)\n",
      "Validation Accuracy: 0.8109 (Error: 0.1891)\n",
      "Testing Accuracy: 0.8196 (Error: 0.1804)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       206\n",
      "           1       0.85      0.82      0.83       254\n",
      "\n",
      "    accuracy                           0.82       460\n",
      "   macro avg       0.82      0.82      0.82       460\n",
      "weighted avg       0.82      0.82      0.82       460\n",
      "\n",
      "Confusion Matrix:\n",
      "[[169  37]\n",
      " [ 46 208]]\n",
      "{'train_error': 0.03260869565217395, 'validation_error': np.float64(0.18914636561695375), 'test_error': 0.1804347826086956, 'best_params': {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'rbf'}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'svm__C': 0.1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Training Accuracy: 0.8438 (Error: 0.1562)\n",
      "Validation Accuracy: 0.8274 (Error: 0.1726)\n",
      "Testing Accuracy: 0.8587 (Error: 0.1413)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83        82\n",
      "           1       0.83      0.93      0.88       102\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.87      0.85      0.85       184\n",
      "weighted avg       0.86      0.86      0.86       184\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63 19]\n",
      " [ 7 95]]\n",
      "{'train_error': 0.15625, 'validation_error': np.float64(0.1725734196117471), 'test_error': 0.14130434782608692, 'best_params': {'svm__C': 0.1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d2.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(svm_pipeline, svm_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312e45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc0f4d27",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f6ad958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'C': 1, 'max_iter': 7000}\n",
      "Training Accuracy: 0.8587 (Error: 0.1413)\n",
      "Validation Accuracy: 0.8206 (Error: 0.1794)\n",
      "Testing Accuracy: 0.8370 (Error: 0.1630)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81       329\n",
      "           1       0.83      0.89      0.86       407\n",
      "\n",
      "    accuracy                           0.84       736\n",
      "   macro avg       0.84      0.83      0.83       736\n",
      "weighted avg       0.84      0.84      0.84       736\n",
      "\n",
      "Confusion Matrix:\n",
      "[[253  76]\n",
      " [ 44 363]]\n",
      "{'train_error': 0.14130434782608692, 'validation_error': np.float64(0.17935836418120932), 'test_error': 0.1630434782608695, 'best_params': {'C': 1, 'max_iter': 7000}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'C': 1, 'max_iter': 7000}\n",
      "Training Accuracy: 0.8457 (Error: 0.1543)\n",
      "Validation Accuracy: 0.8152 (Error: 0.1848)\n",
      "Testing Accuracy: 0.8174 (Error: 0.1826)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       206\n",
      "           1       0.86      0.80      0.83       254\n",
      "\n",
      "    accuracy                           0.82       460\n",
      "   macro avg       0.82      0.82      0.82       460\n",
      "weighted avg       0.82      0.82      0.82       460\n",
      "\n",
      "Confusion Matrix:\n",
      "[[172  34]\n",
      " [ 50 204]]\n",
      "{'train_error': 0.15434782608695652, 'validation_error': np.float64(0.18480321421497903), 'test_error': 0.18260869565217386, 'best_params': {'C': 1, 'max_iter': 7000}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'C': 0.1, 'max_iter': 7000}\n",
      "Training Accuracy: 0.8329 (Error: 0.1671)\n",
      "Validation Accuracy: 0.8247 (Error: 0.1753)\n",
      "Testing Accuracy: 0.8424 (Error: 0.1576)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81        82\n",
      "           1       0.83      0.90      0.86       102\n",
      "\n",
      "    accuracy                           0.84       184\n",
      "   macro avg       0.85      0.84      0.84       184\n",
      "weighted avg       0.84      0.84      0.84       184\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63 19]\n",
      " [10 92]]\n",
      "{'train_error': 0.16711956521739135, 'validation_error': np.float64(0.175283446712018), 'test_error': 0.15760869565217395, 'best_params': {'C': 0.1, 'max_iter': 7000}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d2.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(LogisticRegression(), logistic_reg_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891cb512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef9eab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b65cb2ac",
   "metadata": {},
   "source": [
    "# Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc7dea67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = pd.read_csv('adult.csv')\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c23de3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  \n",
       "0              40  United-States  \n",
       "1              50  United-States  \n",
       "2              40  United-States  \n",
       "3              40  United-States  \n",
       "4              30  United-States  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data3.drop(columns = ['income'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22401bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data3[['income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19355dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>income_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  income  income_binary\n",
       "0  <=50K              0\n",
       "1  <=50K              0\n",
       "2   >50K              1\n",
       "3   >50K              1\n",
       "4  <=50K              0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.assign(income_binary=y['income'].apply(lambda x: 1 if x == '>50K' else 0))\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d785333a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y['income_binary'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01c1930f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11687"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[y==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "516d8363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  \n",
       "0              40  United-States  \n",
       "1              50  United-States  \n",
       "2              40  United-States  \n",
       "3              40  United-States  \n",
       "4              30  United-States  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()#.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8afe68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_columns = [\n",
    "    'workclass', 'education', 'marital-status', \n",
    "    'occupation', 'relationship', 'race', 'native-country'\n",
    "]\n",
    "\n",
    "numerical_columns = ['age','fnlwgt', 'educational-num',\n",
    "       'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "# Create the preprocessing transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_columns),\n",
    "         ('num', StandardScaler(), numerical_columns)\n",
    "    ])\n",
    "\n",
    "def preprocess_data(X):\n",
    "    # Fit and transform the entire dataset\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Get feature names for numerical and categorical columns\n",
    "    num_feature_names = numerical_columns\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns)\n",
    "\n",
    "    # Combine feature names\n",
    "    feature_names = list(num_feature_names) + list(cat_feature_names)\n",
    "\n",
    "    # Create a DataFrame from the transformed array\n",
    "    X_transformed_df = pd.DataFrame(\n",
    "        X_transformed, \n",
    "        columns=feature_names, \n",
    "        index=X.index  # Preserve the original index\n",
    "    )\n",
    "\n",
    "    return X_transformed_df\n",
    "\n",
    "# Optional: If you want to keep numerical columns as well\n",
    "def preprocess_data_full(X):\n",
    "    # Fit and transform the data\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Get feature names for numerical and categorical columns\n",
    "    num_feature_names = numerical_columns\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns)\n",
    "\n",
    "    # Combine feature names\n",
    "    feature_names = list(num_feature_names) + list(cat_feature_names)\n",
    "\n",
    "    # Create a DataFrame from the transformed array\n",
    "    X_transformed_df = pd.DataFrame(\n",
    "        X_transformed, \n",
    "        columns=feature_names, \n",
    "        index=X.index  # Preserve the original index\n",
    "    )\n",
    "\n",
    "    return X_transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e983bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data_full(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33fd783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.995129</td>\n",
       "      <td>0.351675</td>\n",
       "      <td>-1.197259</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046942</td>\n",
       "      <td>-0.945524</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.772930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.776316</td>\n",
       "      <td>1.394723</td>\n",
       "      <td>0.747550</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390683</td>\n",
       "      <td>-0.277844</td>\n",
       "      <td>-0.030373</td>\n",
       "      <td>0.886874</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.505691</td>\n",
       "      <td>-0.815954</td>\n",
       "      <td>-0.030373</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.841104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  educational-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0  0.0     0.0              0.0           0.0           1.0             0.0   \n",
       "1  0.0     0.0              0.0           0.0           1.0             0.0   \n",
       "2  0.0     0.0              1.0           0.0           0.0             0.0   \n",
       "3  0.0     0.0              0.0           0.0           1.0             0.0   \n",
       "4  1.0     0.0              0.0           0.0           0.0             0.0   \n",
       "\n",
       "   workclass_?  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "0          0.0                    0.0                  0.0   \n",
       "1          0.0                    0.0                  0.0   \n",
       "2          0.0                    0.0                  0.0   \n",
       "3          0.0                    0.0                  0.0   \n",
       "4          0.0                    0.0                  0.0   \n",
       "\n",
       "   workclass_Never-worked  ...  native-country_Portugal  \\\n",
       "0                     0.0  ...                      0.0   \n",
       "1                     0.0  ...                      0.0   \n",
       "2                     0.0  ...                      0.0   \n",
       "3                     0.0  ...                      0.0   \n",
       "4                     0.0  ...                      0.0   \n",
       "\n",
       "   native-country_Puerto-Rico  native-country_Scotland  native-country_South  \\\n",
       "0                         1.0                      0.0                   0.0   \n",
       "1                         1.0                      0.0                   0.0   \n",
       "2                         1.0                      0.0                   0.0   \n",
       "3                         1.0                      0.0                   0.0   \n",
       "4                         1.0                      0.0                   0.0   \n",
       "\n",
       "   native-country_Taiwan  native-country_Thailand  \\\n",
       "0              -0.995129                 0.351675   \n",
       "1              -0.046942                -0.945524   \n",
       "2              -0.776316                 1.394723   \n",
       "3               0.390683                -0.277844   \n",
       "4              -1.505691                -0.815954   \n",
       "\n",
       "   native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                       -1.197259                     -0.144804   \n",
       "1                       -0.419335                     -0.144804   \n",
       "2                        0.747550                     -0.144804   \n",
       "3                       -0.030373                      0.886874   \n",
       "4                       -0.030373                     -0.144804   \n",
       "\n",
       "   native-country_Vietnam  native-country_Yugoslavia  \n",
       "0               -0.217127                  -0.034087  \n",
       "1               -0.217127                   0.772930  \n",
       "2               -0.217127                  -0.034087  \n",
       "3               -0.217127                  -0.034087  \n",
       "4               -0.217127                  -0.841104  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdd68f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_d3 = {\n",
    "        \"20/80\": stratified_split_data(X, y, test_size=0.8),\n",
    "        \"50/50\": stratified_split_data(X, y, test_size=0.5),\n",
    "        \"80/20\": stratified_split_data(X, y, test_size=0.2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b756d5",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "343d7607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'max_depth': 20, 'n_estimators': 100}\n",
      "Training Accuracy: 0.9490 (Error: 0.0510)\n",
      "Validation Accuracy: 0.8532 (Error: 0.1468)\n",
      "Testing Accuracy: 0.8624 (Error: 0.1376)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     29724\n",
      "           1       0.77      0.60      0.68      9350\n",
      "\n",
      "    accuracy                           0.86     39074\n",
      "   macro avg       0.83      0.77      0.79     39074\n",
      "weighted avg       0.86      0.86      0.86     39074\n",
      "\n",
      "Confusion Matrix:\n",
      "[[28084  1640]\n",
      " [ 3738  5612]]\n",
      "{'train_error': 0.050982800982800947, 'validation_error': np.float64(0.14680589680589673), 'test_error': 0.13763627987920357, 'best_params': {'max_depth': 20, 'n_estimators': 100}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'max_depth': 20, 'n_estimators': 200}\n",
      "Training Accuracy: 0.9212 (Error: 0.0788)\n",
      "Validation Accuracy: 0.8615 (Error: 0.1385)\n",
      "Testing Accuracy: 0.8631 (Error: 0.1369)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18578\n",
      "           1       0.78      0.60      0.68      5843\n",
      "\n",
      "    accuracy                           0.86     24421\n",
      "   macro avg       0.83      0.77      0.79     24421\n",
      "weighted avg       0.86      0.86      0.86     24421\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17598   980]\n",
      " [ 2363  3480]]\n",
      "{'train_error': 0.07882560091724333, 'validation_error': np.float64(0.1384875607145598), 'test_error': 0.1368903812292699, 'best_params': {'max_depth': 20, 'n_estimators': 200}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'max_depth': 20, 'n_estimators': 100}\n",
      "Training Accuracy: 0.9091 (Error: 0.0909)\n",
      "Validation Accuracy: 0.8620 (Error: 0.1380)\n",
      "Testing Accuracy: 0.8643 (Error: 0.1357)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      7431\n",
      "           1       0.79      0.59      0.68      2338\n",
      "\n",
      "    accuracy                           0.86      9769\n",
      "   macro avg       0.83      0.77      0.80      9769\n",
      "weighted avg       0.86      0.86      0.86      9769\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7059  372]\n",
      " [ 954 1384]]\n",
      "{'train_error': 0.09085557802062805, 'validation_error': np.float64(0.13804940846447566), 'test_error': 0.13573548981472006, 'best_params': {'max_depth': 20, 'n_estimators': 100}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d3.items():\n",
    "        print(f\"\\n--- Results for {partition} Split ---\")\n",
    "        result = evaluate_classifier(rf, params, X_train, X_test, y_train, y_test)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9cfc15",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5eb2d8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 5}\n",
      "Training Accuracy: 0.8744 (Error: 0.1256)\n",
      "Validation Accuracy: 0.8342 (Error: 0.1658)\n",
      "Testing Accuracy: 0.8443 (Error: 0.1557)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     29724\n",
      "           1       0.68      0.67      0.67      9350\n",
      "\n",
      "    accuracy                           0.84     39074\n",
      "   macro avg       0.79      0.78      0.79     39074\n",
      "weighted avg       0.84      0.84      0.84     39074\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26716  3008]\n",
      " [ 3076  6274]]\n",
      "{'train_error': 0.12561425061425058, 'validation_error': np.float64(0.16584766584766586), 'test_error': 0.15570456057736604, 'best_params': {'max_depth': 10, 'min_samples_split': 5}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 5}\n",
      "Training Accuracy: 0.8704 (Error: 0.1296)\n",
      "Validation Accuracy: 0.8553 (Error: 0.1447)\n",
      "Testing Accuracy: 0.8573 (Error: 0.1427)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     18578\n",
      "           1       0.77      0.58      0.66      5843\n",
      "\n",
      "    accuracy                           0.86     24421\n",
      "   macro avg       0.82      0.76      0.78     24421\n",
      "weighted avg       0.85      0.86      0.85     24421\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17566  1012]\n",
      " [ 2473  3370]]\n",
      "{'train_error': 0.1296425207812948, 'validation_error': np.float64(0.14471178585537992), 'test_error': 0.14270504893329516, 'best_params': {'max_depth': 10, 'min_samples_split': 5}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Training Accuracy: 0.8685 (Error: 0.1315)\n",
      "Validation Accuracy: 0.8560 (Error: 0.1440)\n",
      "Testing Accuracy: 0.8615 (Error: 0.1385)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      7431\n",
      "           1       0.77      0.60      0.67      2338\n",
      "\n",
      "    accuracy                           0.86      9769\n",
      "   macro avg       0.83      0.77      0.79      9769\n",
      "weighted avg       0.86      0.86      0.86      9769\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7020  411]\n",
      " [ 942 1396]]\n",
      "{'train_error': 0.13152304660507252, 'validation_error': np.float64(0.14401257936526646), 'test_error': 0.1384993346299519, 'best_params': {'max_depth': 10, 'min_samples_split': 10}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d3.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(dt, params_dt, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017be63e",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4c45efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Training Accuracy: 0.8580 (Error: 0.1420)\n",
      "Validation Accuracy: 0.8276 (Error: 0.1724)\n",
      "Testing Accuracy: 0.8346 (Error: 0.1654)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.90     29724\n",
      "           1       0.70      0.53      0.61      9350\n",
      "\n",
      "    accuracy                           0.83     39074\n",
      "   macro avg       0.78      0.73      0.75     39074\n",
      "weighted avg       0.83      0.83      0.83     39074\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27615  2109]\n",
      " [ 4354  4996]]\n",
      "{'train_error': 0.14199426699426698, 'validation_error': np.float64(0.17239967239967235), 'test_error': 0.16540410503147873, 'best_params': {'n_neighbors': 10, 'weights': 'uniform'}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Training Accuracy: 0.8645 (Error: 0.1355)\n",
      "Validation Accuracy: 0.8374 (Error: 0.1626)\n",
      "Testing Accuracy: 0.8385 (Error: 0.1615)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90     18578\n",
      "           1       0.71      0.55      0.62      5843\n",
      "\n",
      "    accuracy                           0.84     24421\n",
      "   macro avg       0.79      0.74      0.76     24421\n",
      "weighted avg       0.83      0.84      0.83     24421\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17277  1301]\n",
      " [ 2642  3201]]\n",
      "{'train_error': 0.13553908521354574, 'validation_error': np.float64(0.16264694304247185), 'test_error': 0.1614593996969821, 'best_params': {'n_neighbors': 10, 'weights': 'uniform'}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Training Accuracy: 0.8654 (Error: 0.1346)\n",
      "Validation Accuracy: 0.8387 (Error: 0.1613)\n",
      "Testing Accuracy: 0.8438 (Error: 0.1562)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      7431\n",
      "           1       0.73      0.55      0.63      2338\n",
      "\n",
      "    accuracy                           0.84      9769\n",
      "   macro avg       0.80      0.74      0.76      9769\n",
      "weighted avg       0.84      0.84      0.84      9769\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6955  476]\n",
      " [1050 1288]]\n",
      "{'train_error': 0.13461981419394464, 'validation_error': np.float64(0.16126226732752647), 'test_error': 0.15620841437199307, 'best_params': {'n_neighbors': 10, 'weights': 'uniform'}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d3.items():\n",
    "        print(f\"\\n--- Results for {partition} Split ---\")\n",
    "        result = evaluate_classifier(knn, params_knn, X_train, X_test, y_train, y_test)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc4260d",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62278b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'var_smoothing': 1e-07}\n",
      "Training Accuracy: 0.5218 (Error: 0.4782)\n",
      "Validation Accuracy: 0.4600 (Error: 0.5400)\n",
      "Testing Accuracy: 0.5091 (Error: 0.4909)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.37      0.53     29724\n",
      "           1       0.32      0.96      0.48      9350\n",
      "\n",
      "    accuracy                           0.51     39074\n",
      "   macro avg       0.64      0.66      0.51     39074\n",
      "weighted avg       0.81      0.51      0.52     39074\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10940 18784]\n",
      " [  398  8952]]\n",
      "{'train_error': 0.47819410319410316, 'validation_error': np.float64(0.540028665028665), 'test_error': 0.49091467471976247, 'best_params': {'var_smoothing': 1e-07}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'var_smoothing': 1e-07}\n",
      "Training Accuracy: 0.6324 (Error: 0.3676)\n",
      "Validation Accuracy: 0.5848 (Error: 0.4152)\n",
      "Testing Accuracy: 0.6310 (Error: 0.3690)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.54      0.69     18578\n",
      "           1       0.39      0.92      0.54      5843\n",
      "\n",
      "    accuracy                           0.63     24421\n",
      "   macro avg       0.67      0.73      0.62     24421\n",
      "weighted avg       0.82      0.63      0.66     24421\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10059  8519]\n",
      " [  492  5351]]\n",
      "{'train_error': 0.3675525162769747, 'validation_error': np.float64(0.41517368280051004), 'test_error': 0.36898570902092465, 'best_params': {'var_smoothing': 1e-07}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'var_smoothing': 1e-07}\n",
      "Training Accuracy: 0.6349 (Error: 0.3651)\n",
      "Validation Accuracy: 0.5999 (Error: 0.4001)\n",
      "Testing Accuracy: 0.6376 (Error: 0.3624)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.55      0.70      7431\n",
      "           1       0.39      0.91      0.55      2338\n",
      "\n",
      "    accuracy                           0.64      9769\n",
      "   macro avg       0.67      0.73      0.62      9769\n",
      "weighted avg       0.82      0.64      0.66      9769\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4092 3339]\n",
      " [ 201 2137]]\n",
      "{'train_error': 0.3650602717989404, 'validation_error': np.float64(0.40012314486882616), 'test_error': 0.3623707646637322, 'best_params': {'var_smoothing': 1e-07}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d3.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(GaussianNB(), naive_bayes_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa6f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0f7f2a2",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ec0f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'svm__C': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Training Accuracy: 0.8699 (Error: 0.1301)\n",
      "Validation Accuracy: 0.8520 (Error: 0.1480)\n",
      "Testing Accuracy: 0.8450 (Error: 0.1550)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      5956\n",
      "           1       0.72      0.57      0.63      1859\n",
      "\n",
      "    accuracy                           0.85      7815\n",
      "   macro avg       0.80      0.75      0.77      7815\n",
      "weighted avg       0.84      0.85      0.84      7815\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5552  404]\n",
      " [ 807 1052]]\n",
      "{'train_error': 0.13005632360471076, 'validation_error': np.float64(0.14797747055811572), 'test_error': 0.15495841330774152, 'best_params': {'svm__C': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Training Accuracy: 0.8620 (Error: 0.1380)\n",
      "Validation Accuracy: 0.8534 (Error: 0.1466)\n",
      "Testing Accuracy: 0.8509 (Error: 0.1491)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      3746\n",
      "           1       0.74      0.56      0.64      1138\n",
      "\n",
      "    accuracy                           0.85      4884\n",
      "   macro avg       0.81      0.75      0.77      4884\n",
      "weighted avg       0.84      0.85      0.84      4884\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3515  231]\n",
      " [ 497  641]]\n",
      "{'train_error': 0.138001638001638, 'validation_error': np.float64(0.14660114660114665), 'test_error': 0.14905814905814907, 'best_params': {'svm__C': 10, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'svm__C': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Training Accuracy: 0.8574 (Error: 0.1426)\n",
      "Validation Accuracy: 0.8526 (Error: 0.1474)\n",
      "Testing Accuracy: 0.8593 (Error: 0.1407)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1485\n",
      "           1       0.77      0.59      0.67       469\n",
      "\n",
      "    accuracy                           0.86      1954\n",
      "   macro avg       0.83      0.77      0.79      1954\n",
      "weighted avg       0.85      0.86      0.85      1954\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1404   81]\n",
      " [ 194  275]]\n",
      "{'train_error': 0.14256462759150246, 'validation_error': np.float64(0.14742745301534244), 'test_error': 0.14073694984646878, 'best_params': {'svm__C': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}}\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample 20% of the data\n",
    "X_sampled = X.sample(frac=0.2, random_state=42)\n",
    "y_sampled = y[X_sampled.index]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratified sampling\n",
    "X_sampled, _, y_sampled, _ = train_test_split(\n",
    "    X, y, test_size=0.8, stratify=y, random_state=42\n",
    ")\n",
    "# Apply sampling before creating splits\n",
    "X_sampled = X.sample(frac=0.2, random_state=42)\n",
    "y_sampled = y[X_sampled.index]\n",
    "\n",
    "# Create new splits with the sampled data\n",
    "splits_d3_sampled = {\n",
    "    \"20/80\": train_test_split(X_sampled, y_sampled, test_size=0.8, random_state=42),\n",
    "    \"50/50\": train_test_split(X_sampled, y_sampled, test_size=0.5, random_state=42),\n",
    "    \"80/20\": train_test_split(X_sampled, y_sampled, test_size=0.2, random_state=42),\n",
    "}\n",
    "for partition, (X_train, X_test, y_train, y_test) in splits_d3_sampled.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(svm_pipeline, svm_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02d80c-3816-49b8-86d3-63e83bbca15c",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b8106bf-1f5a-4697-8f58-78e2383a9826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for 20/80 Split ---\n",
      "Best parameters: {'C': 0.1, 'max_iter': 7000}\n",
      "Training Accuracy: 0.8448 (Error: 0.1552)\n",
      "Validation Accuracy: 0.8433 (Error: 0.1567)\n",
      "Testing Accuracy: 0.8518 (Error: 0.1482)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     29724\n",
      "           1       0.74      0.58      0.65      9350\n",
      "\n",
      "    accuracy                           0.85     39074\n",
      "   macro avg       0.81      0.76      0.78     39074\n",
      "weighted avg       0.84      0.85      0.85     39074\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27849  1875]\n",
      " [ 3917  5433]]\n",
      "{'train_error': 0.15520065520065518, 'validation_error': np.float64(0.15673628173628185), 'test_error': 0.14823156062855092, 'best_params': {'C': 0.1, 'max_iter': 7000}}\n",
      "\n",
      "--- Results for 50/50 Split ---\n",
      "Best parameters: {'C': 1, 'max_iter': 7000}\n",
      "Training Accuracy: 0.8528 (Error: 0.1472)\n",
      "Validation Accuracy: 0.8512 (Error: 0.1488)\n",
      "Testing Accuracy: 0.8540 (Error: 0.1460)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     18578\n",
      "           1       0.74      0.60      0.66      5843\n",
      "\n",
      "    accuracy                           0.85     24421\n",
      "   macro avg       0.81      0.77      0.78     24421\n",
      "weighted avg       0.85      0.85      0.85     24421\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17367  1211]\n",
      " [ 2354  3489]]\n",
      "{'train_error': 0.14716842062159619, 'validation_error': np.float64(0.14884745830575585), 'test_error': 0.14598091806232338, 'best_params': {'C': 1, 'max_iter': 7000}}\n",
      "\n",
      "--- Results for 80/20 Split ---\n",
      "Best parameters: {'C': 10, 'max_iter': 7000}\n",
      "Training Accuracy: 0.8540 (Error: 0.1460)\n",
      "Validation Accuracy: 0.8524 (Error: 0.1476)\n",
      "Testing Accuracy: 0.8533 (Error: 0.1467)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      7431\n",
      "           1       0.74      0.60      0.66      2338\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.85      0.85      0.85      9769\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6944  487]\n",
      " [ 946 1392]]\n",
      "{'train_error': 0.14595756660609627, 'validation_error': np.float64(0.14757004146879404), 'test_error': 0.14668850445286108, 'best_params': {'C': 10, 'max_iter': 7000}}\n"
     ]
    }
   ],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d3.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(LogisticRegression(), logistic_reg_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition, (X_train, X_test, y_train, y_test) in splits_d3.items():\n",
    "    print(f\"\\n--- Results for {partition} Split ---\")\n",
    "    result = evaluate_classifier(svm_pipeline, svm_params, X_train, X_test, y_train, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5ad2f",
   "metadata": {},
   "source": [
    "# Data 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1dd526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3272c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58570e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
